# Layer 2: Data Processing Components

**ğŸ”¨ Build and validate modular data processing components (datakits)**

This layer focuses on building individual, reusable data processing tools. Pipeline orchestration and integration testing happen in Layer 3.

## ğŸ“‹ Prerequisites

You must have completed **Layer 1: Platform Foundation** setup:
- âœ… Traefik reverse proxy running at https://traefik.localhost
- âœ… Container registry available at https://registry.localhost
- âœ… Platform validation passed: `ansible-playbook -i ansible/inventory/local-dev.ini ansible/validate-all.yml --ask-become-pass`

## ğŸ¯ Component Philosophy

**Layer 2 Focus**: Build and test individual components
**Layer 3 Focus**: Orchestrate components into pipelines

```
ğŸ”¨ Build â†’ ğŸ§ª Test â†’ âœ… Validate â†’ ğŸ“¦ Package
```

### Datakit Components
```
Individual Processing Tools (not connected pipelines):
â”œâ”€â”€ bronze-pagila     â†’ Raw data ingestion with audit trails
â”œâ”€â”€ postgres-runner   â†’ PostgreSQL operations and utilities
â”œâ”€â”€ dbt-runner        â†’ DBT transformations orchestration
â”œâ”€â”€ sqlserver-runner  â†’ SQL Server operations and utilities
â””â”€â”€ spark-runner      â†’ Spark processing for large datasets (optional)

DBT Projects (SQL transformations):
â”œâ”€â”€ silver-core       â†’ Data cleaning and conformance
â”œâ”€â”€ gold-dimensions   â†’ Slowly changing dimensions
â””â”€â”€ gold-facts        â†’ Fact tables and metrics
```

## ğŸš€ Quick Start

### Step 1: Build Components
```bash
# Build all datakit container images
./scripts/build-layer2-components.sh

# Optional: Build complex components like Spark
./scripts/build-layer2-components.sh --build-optional
```

### Step 2: Test Components
```bash
# Run unit tests for all components
./scripts/test-layer2-components.sh

# Test specific component
./scripts/test-layer2-components.sh bronze-pagila
```

### Step 3: Clean Up (When Needed)
```bash
# Remove all components
./scripts/teardown-layer2.sh --full-clean

# Keep built images for faster rebuilds
./scripts/teardown-layer2.sh --preserve-images
```

## ğŸ”§ Component Details

### Built Images
After successful build, you'll have:
- `registry.localhost/datakits/bronze-pagila:v1.0.0`
- `registry.localhost/datakits/postgres-runner:v1.0.0`
- `registry.localhost/datakits/dbt-runner:v1.0.0`
- `registry.localhost/datakits/sqlserver-runner:v1.0.0`

### DBT Projects
- **silver-core**: Data cleaning and validation transformations
- **gold-dimensions**: Slowly changing dimension management
- **gold-facts**: Fact table creation and metrics

## ğŸ§ª Testing

### Unit Tests
Each component includes tests that validate:
- âœ… Container builds successfully
- âœ… Python packages install correctly
- âœ… CLI tools are accessible
- âœ… Basic functionality works

### Test Coverage
```bash
# Test all components
./scripts/test-layer2-components.sh

# Expected output:
# âœ… bronze-pagila: Container builds, CLI accessible
# âœ… postgres-runner: Container builds, CLI accessible
# âœ… dbt-runner: Container builds, DBT available
# âœ… sqlserver-runner: Container builds, CLI accessible
```

## ğŸ§¹ Teardown Options

### Quick Reference Commands
```bash
./scripts/teardown-layer2.sh --help         # Show all options
./scripts/teardown-layer2.sh --full-clean   # Remove everything
./scripts/teardown-layer2.sh --preserve-images  # Keep images, clean temp files
```

### Teardown Modes
- **--full-clean**: Remove all images and artifacts
- **--preserve-images**: Keep built images for fast rebuilds
- **Interactive**: Choose what to clean (default)

## ğŸš¨ Troubleshooting

### Quick Reference Commands

**Build Issues**:
```bash
# Check build logs
ls /tmp/build_*.log

# Rebuild single component
./scripts/build-layer2-components.sh --component bronze-pagila
```

**Test Issues**:
```bash
# Test single component with verbose output
./scripts/test-layer2-components.sh bronze-pagila --verbose

# Check container logs
docker logs test-bronze-pagila
```

### Common Issues

**Build Failures**:
- Check `/tmp/build_*.log` for detailed error messages
- Verify Layer 1 registry is accessible: `curl -k https://registry.localhost/v2/_catalog`

**Test Failures**:
- Verify Docker daemon is running: `docker info`
- Check component-specific logs for detailed errors

## ğŸš€ Next Steps

After Layer 2 validation passes:

1. **Move to Layer 3**: Orchestration and pipeline integration
2. **Integration Testing**: Use Layer 3 to test component interactions
3. **Production Deployment**: Use validated components in real pipelines

## ğŸ“ Project Structure

```
layer2-datakits/           # Component source code
â”œâ”€â”€ bronze-pagila/         # Raw data ingestion
â”œâ”€â”€ postgres-runner/       # PostgreSQL utilities
â”œâ”€â”€ dbt-runner/           # DBT orchestration
â”œâ”€â”€ sqlserver-runner/     # SQL Server utilities
â””â”€â”€ spark-runner/         # Spark processing (optional)

layer2-dbt-projects/      # SQL transformation projects
â”œâ”€â”€ silver-core/          # Data cleaning
â”œâ”€â”€ gold-dimensions/      # Dimension tables
â””â”€â”€ gold-facts/           # Fact tables

scripts/                  # Component management
â”œâ”€â”€ build-layer2-components.sh   # Build all components
â”œâ”€â”€ test-layer2-components.sh    # Test all components
â””â”€â”€ teardown-layer2.sh          # Clean up components
```

---

**ğŸ¯ Layer 2 Objective**: Prove that individual components work in isolation.
**ğŸ¯ Layer 3 Objective**: Prove that components work together in pipelines.

ğŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>
